{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLTFsLAN6YCOLALqUyGXaz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepak427/colab-projects/blob/main/Chatbot_using_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import dependencies"
      ],
      "metadata": {
        "id": "p1CnyS526Zz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "import string\n",
        "import json\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow. keras import Sequential\n",
        "import tensorflow as tf\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "import nltk\n",
        "import random"
      ],
      "metadata": {
        "id": "vCFHfO9D6buZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset creation"
      ],
      "metadata": {
        "id": "E7eulZVl64ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\"intents\": [\n",
        "    {\"tag\": \"greeting\",\n",
        "     \"patterns\": [\"Hello\", \"How are you?\", \"Hi There\", \"Hi\", \"What's up\"],\n",
        "     \"responses\": [\"Namaste!\", \"Howdy Partner!\", \"Hello\", \"How are you doing?\", \"Greetings!\", \"How do you do\"]\n",
        "     },\n",
        "    {\"tag\": \"age\",\n",
        "     \"patterns\": [\"how old are you\", \"when is your birthday\", \"when was you born\"],\n",
        "     \"responses\": [\"I am 21 years old\", \"I was born in 1966\", \"My birthday is feb 18th and I was born in 2003\", \"18/02/2003\"]},\n",
        "    {\"tag\": \"date\",\n",
        "     \"patterns\": [\"what are you doing this weekend\", \"do you want to hangout sometime?\", \"what are your plans for this week\"],\n",
        "     \"responses\": [\"I am available this week\", \"I don't have any plans\", \"I am not busy\"]\n",
        "     },\n",
        "    {\"tag\": \"name\",\n",
        "     \"patterns\": [\"what's your name\", \"what are you called\", \"who are you\"],\n",
        "     \"responses\": [\"My name is Deepak\", \"I'm Deepak\", \"Deepak\"]\n",
        "     },\n",
        "    {\"tag\": \"goodbye\",\n",
        "     \"patterns\": [\"bye\", \"g2g\", \"see ya\", \"adios\", \"cya\", \"Goodbye\"],\n",
        "     \"responses\": [\"It was nice speaking to you\", \"See you later\", \"Speak Soon\", \"Bye\"]},\n",
        "]}"
      ],
      "metadata": {
        "id": "oaJDUyxF6jkM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization and lemmatization"
      ],
      "metadata": {
        "id": "RSSW5n3H8VBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = []\n",
        "classes = []\n",
        "doc_x = []\n",
        "doc_y = []\n",
        "\n",
        "for intent in data[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        tokens = nltk.word_tokenize(pattern)\n",
        "        words.extend(tokens)\n",
        "        doc_x.append(pattern)\n",
        "        doc_y.append(intent[\"tag\"])\n",
        "    if intent[\"tag\"] not in classes:\n",
        "        classes.append(intent[\"tag\"])\n",
        "\n",
        "words = [lemmatizer.lemmatize(word.lower())\n",
        "         for word in words if word not in string.punctuation]\n",
        "\n",
        "# Removing duplicates\n",
        "words = sorted(set(words))\n",
        "classes = sorted(set(classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-381VzO163Gu",
        "outputId": "75a446c0-d191-4198-dc52-0bed86c02fd8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing training data"
      ],
      "metadata": {
        "id": "xUMqBT_r-I2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training = []\n",
        "out_empty = [0]*len(classes)\n",
        "\n",
        "# Bag of words model\n",
        "for idx, doc in enumerate(doc_x):\n",
        "    bow = []\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    text = [lemmatizer.lemmatize(word.lower()) for word in tokens if word not in string.punctuation]\n",
        "    for word in words:\n",
        "        bow.append(1) if word in text else bow.append(0)\n",
        "    output_row = list(out_empty)\n",
        "    output_row[classes.index(doc_y[idx])] = 1\n",
        "\n",
        "    training.append([bow, output_row])\n",
        "\n",
        "random.shuffle(training)\n",
        "\n",
        "training = np.array(training, dtype=object)\n",
        "\n",
        "train_X = np.array(list(training[:, 0]))\n",
        "train_y = np.array(list(training[:, 1]))"
      ],
      "metadata": {
        "id": "IE-8fHJf8TEK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating sequential model"
      ],
      "metadata": {
        "id": "y6bealw_E2uD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (len(train_X[0]),)\n",
        "output_shape = len(train_y[0])\n",
        "\n",
        "epochs = 500\n",
        "\n",
        "# Sequential model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=input_shape, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(output_shape, activation='softmax'))\n",
        "\n",
        "# Adam optimizer with a specified Learning rate\n",
        "adam = tf.keras.optimizers. Adam(learning_rate=0.01)"
      ],
      "metadata": {
        "id": "9MUGNErEExq7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile and train model"
      ],
      "metadata": {
        "id": "W2kktKMDFMQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(x=train_X, y=train_y, epochs=epochs, verbose=1)"
      ],
      "metadata": {
        "id": "TuOhvTAME8ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing of input"
      ],
      "metadata": {
        "id": "nasBBVHDJB7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    tokens=nltk.word_tokenize(text)\n",
        "    tokens=[lemmatizer.lemmatize(word.lower()) for word in tokens]\n",
        "    return tokens\n",
        "\n",
        "def bag_of_words(text, vocab):\n",
        "    tokens=clean_text(text)\n",
        "    bow=[0]*len(vocab)\n",
        "    for w in tokens:\n",
        "        for idx, word in enumerate(vocab):\n",
        "            if word==w:\n",
        "                bow[idx]=1\n",
        "    return np.array(bow)\n",
        "\n",
        "def pred_class (text, vocab,labels):\n",
        "    bow=bag_of_words(text, vocab)\n",
        "    result=model.predict(np.array([bow]))[0]\n",
        "    thresh=0.2\n",
        "    y_pred=[[idx, res] for idx, res in enumerate(result) if res>thresh]\n",
        "\n",
        "    y_pred.sort(key=lambda x:x[1], reverse=True)\n",
        "    return_list=[]\n",
        "    for r in y_pred:\n",
        "        return_list.append(labels[r[0]])\n",
        "    return return_list"
      ],
      "metadata": {
        "id": "VMEnS0iYFQTn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get response"
      ],
      "metadata": {
        "id": "L77rQevXKYHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(intents_list, intents_json):\n",
        "    tag=intents_list[0]\n",
        "    list_of_intents=intents_json[\"intents\"]\n",
        "    for i in list_of_intents:\n",
        "        if i[\"tag\"]==tag:\n",
        "            result=random.choice (i[\"responses\"])\n",
        "            break\n",
        "    return result\n",
        "\n",
        "while True:\n",
        "    message=input(\"\")\n",
        "    intents=pred_class(message.lower(), words, classes)\n",
        "    result=get_response(intents, data)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "n4ZBwbJpJF3V",
        "outputId": "c4624abc-1af3-4761-d348-70ed64126f39"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-4ed6cbeacea5>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mintents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NT8E4efCKt23"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}