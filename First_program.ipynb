{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzZsDogArd8TB+9pRaUnvf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepak427/colab-projects/blob/main/First_program.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9t_01BO3LbsT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'class']\n",
        "df = pd.read_csv('magic04.data', names=cols)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "6KruX50SMroo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['class'] = (df['class'] == 'g').astype(int)"
      ],
      "metadata": {
        "id": "yPnimnXDO8vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "v4lZWj1-TBOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label in cols[:-1]:\n",
        "  plt.hist(df[df['class'] == 1][label], color='blue', label='gamma', alpha=0.7, density=True)\n",
        "  plt.hist(df[df['class'] == 0][label], color='red', label='hadron', alpha=0.7, density=True)\n",
        "  plt.title(label)\n",
        "  plt.ylabel('probability')\n",
        "  plt.xlabel(label)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "H-gDHXnvbVPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, valid, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8*len(df))])"
      ],
      "metadata": {
        "id": "zH4L7h9ecf6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_dataset(dataframe, oversample=False):\n",
        "  x = dataframe[dataframe.columns[:-1]].values\n",
        "  y = dataframe[dataframe.columns[-1]].values\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  x = scaler.fit_transform(x)\n",
        "\n",
        "  if oversample:\n",
        "    ros = RandomOverSampler()\n",
        "    x, y =ros.fit_resample(x, y)\n",
        "\n",
        "  data = np.hstack((x, np.reshape(y, (-1, 1))))\n",
        "\n",
        "  return data, x, y"
      ],
      "metadata": {
        "id": "S9Ju6a02laFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, x_train, y_train = scale_dataset(train, oversample=True)\n",
        "valid, x_valid, y_valid = scale_dataset(valid)\n",
        "test, x_test, y_test = scale_dataset(test)"
      ],
      "metadata": {
        "id": "iy6phVjMo97H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# kNN"
      ],
      "metadata": {
        "id": "zOfQh85gwNhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "N33hdlaXqdVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "84UdlySswIF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = knn_model.predict(x_test)"
      ],
      "metadata": {
        "id": "YeCgKYYLwuPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "wugE49-0w-_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes"
      ],
      "metadata": {
        "id": "-TI_yNtdaVMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "eJnGEt4RxN6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_model = GaussianNB()\n",
        "nb_model = nb_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "Nn40rgILaf2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = nb_model.predict(x_test)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "q5D57dU3ap3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log Regression"
      ],
      "metadata": {
        "id": "OIWlOPe8zz10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "8ORrJVUUbArR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lg_model = LogisticRegression()\n",
        "lg_model = lg_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "LQ48N5dp0QPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = lg_model.predict(x_test)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "D4tw2RGR0hqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM"
      ],
      "metadata": {
        "id": "7PQNzVlU3ma0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "b8vEHsQp0lJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC()\n",
        "svm_model = svm_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "9J9AjBjb3zu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm_model.predict(x_test)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "6NrfL3rS3-lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Net"
      ],
      "metadata": {
        "id": "w_dPQED67qER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "DpxTu-3w4GfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "  ax1.plot(history.history['loss'], label='loss')\n",
        "  ax1.plot(history.history['val_loss'], label='val_loss')\n",
        "  ax1.set_xlabel('Epoch')\n",
        "  ax1.set_ylabel('Binary crossentropy')\n",
        "  ax1.grid(True)\n",
        "\n",
        "  ax2.plot(history.history['accuracy'], label='accuracy')\n",
        "  ax2.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "  ax2.set_xlabel('Epoch')\n",
        "  ax2.set_ylabel('Accuracy')\n",
        "  ax2.grid(True)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "AwqYM-To-Hob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X_train, y_train, num_nodes, dropout_prob, lr, batch_size, epochs):\n",
        "  nn_model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(num_nodes, activation='relu', input_shape=(10,)),\n",
        "      tf.keras.layers.Dropout(dropout_prob),\n",
        "      tf.keras.layers.Dense(num_nodes, activation='relu'),\n",
        "      tf.keras.layers.Dropout(dropout_prob),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  nn_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  history = nn_model.fit(\n",
        "    X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0\n",
        "  )\n",
        "\n",
        "  return nn_model, history"
      ],
      "metadata": {
        "id": "k5wGgcA67vcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "least_val_loss = float('inf')\n",
        "least_loss_model = None\n",
        "epochs=100\n",
        "for num_nodes in [16, 32, 64]:\n",
        "  for dropout_prob in[0, 0.2]:\n",
        "    for lr in [0.01, 0.005, 0.001]:\n",
        "      for batch_size in [32, 64, 128]:\n",
        "        print(f\"{num_nodes} nodes, dropout {dropout_prob}, lr {lr}, batch size {batch_size}\")\n",
        "        model, history = train_model(x_train, y_train, num_nodes, dropout_prob, lr, batch_size, epochs)\n",
        "        plot_history(history)\n",
        "        val_loss = model.evaluate(x_valid, y_valid)[0]\n",
        "        if val_loss < least_val_loss:\n",
        "          least_val_loss = val_loss\n",
        "          least_loss_model = model"
      ],
      "metadata": {
        "id": "giZsvCGj_WnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = least_loss_model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5).astype(int).reshape(-1,)"
      ],
      "metadata": {
        "id": "fSZ0pMTXD_am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Z2ntvdjvp08F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}